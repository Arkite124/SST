from kiwipiepy import Kiwi
from sqlalchemy.orm import Session
from sqlalchemy import text
import random, torch, re, os, json
from transformers import AutoTokenizer, AutoModelForSeq2SeqLM
from peft import PeftModel, PeftConfig

BASE_DIR = os.path.dirname(os.path.abspath(__file__))  # í˜„ì¬ íŒŒì¼ ìœ„ì¹˜
filepath = os.path.join(BASE_DIR, "data/labeled_fairytale.json")

class ReadingAssessment:
    # í´ë˜ìŠ¤ ë³€ìˆ˜ë¡œ ëª¨ë¸ ë¡œë“œ (ëª¨ë“  ì¸ìŠ¤í„´ìŠ¤ê°€ ê³µìœ )
    _model = None
    _tokenizer = None
    _device = None
    _model_loaded = False

    @classmethod
    def _load_model(cls):
        """ëª¨ë¸ì„ í•œ ë²ˆë§Œ ë¡œë“œ (í´ë˜ìŠ¤ ë©”ì„œë“œ)"""
        if cls._model_loaded:
            return

        MODEL_DIR = "eunchea/t5_fairytale_read"
        cls._device = "cuda" if torch.cuda.is_available() else "cpu"

        try:
            config = PeftConfig.from_pretrained(MODEL_DIR)
            base = AutoModelForSeq2SeqLM.from_pretrained(config.base_model_name_or_path)
            cls._model = PeftModel.from_pretrained(base, MODEL_DIR).to(cls._device)
            cls._tokenizer = AutoTokenizer.from_pretrained(MODEL_DIR)
            cls._model.eval()
            cls._model_loaded = True
            print("âœ… T5 LoRA ëª¨ë¸ ë¡œë“œ ì™„ë£Œ")
        except Exception as e:
            print(f"âš ï¸ T5 ëª¨ë¸ ë¡œë“œ ì‹¤íŒ¨: {e}")
            print("ğŸ”„ ê¸°ë³¸ T5 ëª¨ë¸ì„ ì‚¬ìš©í•©ë‹ˆë‹¤...")

            try:
                # LoRA ì—†ì´ ê¸°ë³¸ T5 ëª¨ë¸ë§Œ ë¡œë“œ
                from transformers import T5ForConditionalGeneration, T5Tokenizer

                base_model = "psyche/KoT5-summarization"  # ë˜ëŠ” "google/mt5-small"
                cls._model = T5ForConditionalGeneration.from_pretrained(base_model).to(cls._device)
                cls._tokenizer = T5Tokenizer.from_pretrained(base_model)
                cls._model.eval()
                cls._model_loaded = True
                print(f"âœ… ê¸°ë³¸ T5 ëª¨ë¸ ë¡œë“œ ì™„ë£Œ: {base_model}")
            except Exception as e2:
                print(f"âŒ ê¸°ë³¸ T5 ëª¨ë¸ ë¡œë“œë„ ì‹¤íŒ¨: {e2}")
                cls._model = None
                cls._tokenizer = None

    def __init__(self, db_session: Session = None):
        """
        Args:
            db_session: DB ì„¸ì…˜ (ì„ë² ë”© ê¸°ë°˜ ì˜¤ë‹µ ìƒì„±ìš©)
        """
        # ëª¨ë¸ì´ ì•„ì§ ë¡œë“œë˜ì§€ ì•Šì•˜ë‹¤ë©´ ë¡œë“œ
        if not self.__class__._model_loaded:
            self.__class__._load_model()
        self.db = db_session
        self.kiwi = Kiwi()

    def clean_question(self, text: str) -> str:
        """ì§ˆë¬¸ ë¬¸ì¥ì„ ìì—°ìŠ¤ëŸ½ê²Œ ë‹¤ë“¬ëŠ” ê°„ë‹¨í•œ í›„ì²˜ë¦¬"""
        q = text.strip()

        # 1ï¸âƒ£ ë¶ˆí•„ìš”í•œ ë°˜ë³µ êµ¬ë¬¸ ì œê±°
        q = re.sub(r"(ëˆ„ê°€|ë¬´ì—‡ì´)\s+\1", r"\1", q)

        # 2ï¸âƒ£ '~ëœ ê²ƒì€ ëˆ„êµ¬ì¼ê¹Œìš”?' â†’ '~ë˜ì—ˆë‚˜ìš”?' í˜•íƒœë¡œ ë³€í™˜
        q = re.sub(r"ëœ ê²ƒì€ ëˆ„êµ¬ì…ë‹ˆê¹Œ[?ï¼Ÿ]?", "ë˜ì—ˆë‚˜ìš”?", q)
        q = re.sub(r"ëœ ê²ƒì€ ëˆ„êµ¬ì¼ê¹Œìš”[?ï¼Ÿ]?", "ë˜ì—ˆë‚˜ìš”?", q)

        # 3ï¸âƒ£ 'ëˆ„ê°€ .* ëˆ„êµ¬(ì…ë‹ˆê¹Œ|ì¼ê¹Œìš”)' â†’ 'ëˆ„ê°€ .* í–ˆë‚˜ìš”?'
        q = re.sub(r"ëˆ„ê°€\s+(.+)\s+ëˆ„êµ¬(ì…ë‹ˆê¹Œ|ì¼ê¹Œìš”)\??", r"ëˆ„ê°€ \1 í–ˆë‚˜ìš”?", q)

        # 4ï¸âƒ£ ì–´ë¯¸ ë³´ì •: ë¬¼ìŒí‘œê°€ ì—†ìœ¼ë©´ ë¶™ì´ê¸°
        if not q.endswith("?"):
            q += "?"

        # 5ï¸âƒ£ '~ê°€', '~ì€' ê°™ì€ ì¡°ì‚¬ê°€ ì—†ì„ ë•Œ ìµœì†Œí•œì˜ í˜•íƒœ ë³´ì •
        if not re.search(r"[ê°€-í£]{1,3}(ê°€|ì´|ì€|ëŠ”|ë¥¼|ì„)", q):
            q = re.sub(r"(ëˆ„ê°€|ë¬´ì—‡ì´|ì–´ë””ì„œ|ì–¸ì œ|ì™œ|ì–´ë–»ê²Œ)", r"\1ëŠ”", q)

        # 6ï¸âƒ£ ë§ˆì§€ë§‰ ë§ˆë¬´ë¦¬ ê³µë°± ì •ë¦¬
        q = re.sub(r"\s+", " ", q).strip()

        return q

    def _extract_nouns_from_paragraph(self, paragraph: str) -> list[str]:
        """Kiwië¥¼ ì‚¬ìš©í•´ ë¬¸ë‹¨ì—ì„œ ëª…ì‚¬ ì¶”ì¶œ"""
        result = self.kiwi.analyze(paragraph)
        nouns = []

        for token in result[0][0]:
            # ì¼ë°˜ëª…ì‚¬(NNG), ê³ ìœ ëª…ì‚¬(NNP)ë§Œ ì¶”ì¶œ
            if token.tag in ['NNG', 'NNP'] and len(token.form) >= 2:
                nouns.append(token.form)

        return list(set(nouns))  # ì¤‘ë³µ ì œê±°

    def _find_similar_words_from_db(self, correct_answer: str, limit: int = 10) -> list[str]:
        """DBì—ì„œ ì„ë² ë”© ìœ ì‚¬ë„ ê¸°ë°˜ìœ¼ë¡œ ìœ ì‚¬ ë‹¨ì–´ ì°¾ê¸°"""
        if not self.db:
            return []

        try:
            # voca_labels í…Œì´ë¸” ë‚´ì—ì„œ ì„ë² ë”© ìœ ì‚¬ë„ ê³„ì‚°
            query = text("""
                        SELECT v2.word, 1 - (v1.embedding <=> v2.embedding) AS similarity
                        FROM voca_labels v1
                        JOIN voca_labels v2 ON v1.word != v2.word
                        WHERE v1.word = :correct_answer
                        -- ğŸ¯ ìœ ì‚¬ë„ê°€ 0.5 ì´í•˜ì¸ ë‹¨ì–´ë§Œ ì„ íƒ (ê±°ë¦¬ >= 0.5)
                        AND (v1.embedding <=> v2.embedding) >= 0.5 
                        ORDER BY 
                            -- ğŸ¯ ê±°ë¦¬ê°€ ê°€ì¥ ë¨¼(ìœ ì‚¬ë„ê°€ ê°€ì¥ ë‚®ì€) ë‹¨ì–´ë¶€í„° ì •ë ¬
                            v1.embedding <=> v2.embedding DESC
                        LIMIT :limit
                    """)

            result = self.db.execute(
                query,
                {"correct_answer": correct_answer, "limit": limit}
            )

            similar_words = [row[0] for row in result.fetchall()]
            return similar_words

        except Exception as e:
            print(f"âš ï¸ DB ìœ ì‚¬ë„ ê²€ìƒ‰ ì‹¤íŒ¨: {e}")
            return []

    # ğŸ”¹ í›„ë³´ í•„í„°ë§ ë¡œì§
    def _is_valid_distractor(self, word: str, answer: str) -> bool:
        word = word.strip()
        # 1ï¸âƒ£ ê¸¸ì´ ì œí•œ
        if len(word) < 2 or len(word) > 5:
            return False
        # 2ï¸âƒ£ ì •ë‹µê³¼ ë¶€ë¶„ì ìœ¼ë¡œ 2ê¸€ì ì´ìƒ ê²¹ì¹˜ë©´ ì œì™¸
        for i in range(len(answer) - 1):
            sub = answer[i:i + 2]
            if sub in word:
                return False
        # 3ï¸âƒ£ í•œê¸€ ì™¸ ë¬¸ì í¬í•¨ ì‹œ ì œì™¸
        if not re.fullmatch(r"[ê°€-í£]+", word):
            return False
        # 4ï¸âƒ£ ì •ë‹µê³¼ ë™ì¼í•˜ë©´ ì œì™¸
        if word == answer:
            return False
        return True

    def _generate_distractors_from_list(
            self,
            correct_answer: str,
            candidate_words: list[str],
            max_count: int = 3
    ) -> list[str]:
        """í›„ë³´ ë‹¨ì–´ ë¦¬ìŠ¤íŠ¸ì—ì„œ ì˜¤ë‹µ ìƒì„± (í•„í„°ë§ + ì •ë ¬)"""
        # í•„í„°ë§
        filtered = [w for w in candidate_words if self._is_valid_distractor(w, correct_answer)]

        # ì¤‘ë³µ ì œê±°
        filtered = list(dict.fromkeys(filtered))

        # ê°„ë‹¨í•œ ìœ ì‚¬ë„ ê³„ì‚° (ë¬¸ìì—´ ê¸°ë°˜)
        def simple_similarity(word1, word2):
            return sum(a == b for a, b in zip(word1, word2)) / max(len(word1), len(word2))

        # ìœ ì‚¬ë„ ê¸°ë°˜ ì •ë ¬
        filtered.sort(key=lambda w: simple_similarity(w, correct_answer), reverse=True)

        return filtered[:max_count]

    def _generate_distractors(
            self,
            correct_answer: str,
            paragraph: str,
            db_words: list[str] = None,
            age_level: int = 7
    ) -> list[str]:
        """ì˜¤ë‹µ ì„ íƒì§€ ìƒì„± (ì„ë² ë”© ìœ ì‚¬ë„ ê¸°ë°˜)"""
        distractors = []

        # 1ìˆœìœ„: DB ì„ë² ë”© ìœ ì‚¬ë„
        if self.db:
            similar_words = self._find_similar_words_from_db(correct_answer, limit=10)
            distractors.extend(self._generate_distractors_from_list(correct_answer, similar_words, 5))

        # 2ìˆœìœ„: db_words ë¦¬ìŠ¤íŠ¸ì—ì„œ ì„ íƒ
        if len(distractors) < 3 and db_words:
            remaining = self._generate_distractors_from_list(correct_answer, db_words, 5)
            distractors.extend(remaining)

        # 3ìˆœìœ„: ê°™ì€ ë¬¸ë‹¨ì˜ ëª…ì‚¬
        if len(distractors) < 3:
            paragraph_nouns = self._extract_nouns_from_paragraph(paragraph)
            remaining = self._generate_distractors_from_list(correct_answer, paragraph_nouns, 3)
            distractors.extend(remaining)

        # 4ìˆœìœ„: DBì—ì„œ ê°™ì€ ë‚œì´ë„ ëœë¤
        if len(distractors) < 3 and self.db:
            try:
                query = text("""
                            SELECT word FROM voca_labels
                            WHERE assigned_age BETWEEN :min_age AND :max_age
                            AND word != :correct_answer
                            AND LENGTH(word) >= 2
                            ORDER BY RANDOM()
                            LIMIT 10
                        """)

                result = self.db.execute(
                    query,
                    {
                        "min_age": age_level - 1,
                        "max_age": age_level + 1,
                        "correct_answer": correct_answer
                    }
                )

                random_words = [row[0] for row in result.fetchall()]
                remaining = self._generate_distractors_from_list(correct_answer, random_words, 5)
                distractors.extend(remaining)

            except Exception as e:
                print(f"âš ï¸ DB ëœë¤ ê²€ìƒ‰ ì‹¤íŒ¨: {e}")

        # ìµœì¢… ì¤‘ë³µ ì œê±°
        distractors = list(dict.fromkeys(distractors))
        return distractors[:3]

    def _parse_t5_output(self, raw_output: str) -> dict:
        """T5 ëª¨ë¸ ì¶œë ¥ íŒŒì‹±"""
        question, answer = None, None

        if "ë‹µ:" in raw_output or "ì •ë‹µ:" in raw_output:
            try:
                # "ë‹µ:" ë˜ëŠ” "ì •ë‹µ:" ê¸°ì¤€ìœ¼ë¡œ ë¶„ë¦¬
                if "ì •ë‹µ:" in raw_output:
                    parts = raw_output.split("ì •ë‹µ:", 1)
                else:
                    parts = raw_output.split("ë‹µ:", 1)

                question_part = parts[0].strip()

                # "ì§ˆë¬¸:" ë˜ëŠ” "Q:" ì œê±°
                for prefix in ["ì§ˆë¬¸:", "Q:", "ì§ˆë¬¸ :", "Q :"]:
                    if question_part.startswith(prefix):
                        question_part = question_part.replace(prefix, "", 1).strip()

                # ë¬¼ìŒí‘œê¹Œì§€ê°€ ì§ˆë¬¸
                if '?' in question_part:
                    question = question_part.split('?')[0].strip() + '?'
                else:
                    question = question_part

                # ì •ë‹µ ë¶€ë¶„
                answer = parts[1].strip()

            except Exception as e:
                print(f"âš ï¸ T5 ì¶œë ¥ íŒŒì‹± ì‹¤íŒ¨: {e}")
                question = raw_output.strip()
                answer = None
        else:
            # íŒŒì‹± íŒ¨í„´ì´ ì—†ìœ¼ë©´ ì „ì²´ë¥¼ ì§ˆë¬¸ìœ¼ë¡œ ì²˜ë¦¬
            question = raw_output.strip()
            answer = None

        return {"question": question, "answer": answer}

    def create_question_from_qna(
            self,
            paragraph: str,
            qna_result: dict,
            age_level: int = 7
    ) -> dict:
        """
        QnAë¥¼ 4ì§€ì„ ë‹¤ í˜•ì‹ìœ¼ë¡œ ë³€í™˜

        Args:
            paragraph: ì›ë³¸ ë¬¸ë‹¨
            qna_result: generate_qna_from_paragraphì˜ ê²°ê³¼
            age_level: ë‚œì´ë„

        Returns:
            dict: 4ì§€ì„ ë‹¤ ë¬¸ì œ
        """
        question = qna_result.get("question")
        correct_answer = qna_result.get("answer")
        distractors = qna_result.get("distractors", [])
        choices = qna_result.get("choices", [])

        if not question or not correct_answer:
            raise ValueError("ì§ˆë¬¸ ë˜ëŠ” ì •ë‹µì´ ì—†ìŠµë‹ˆë‹¤.")

        # choicesê°€ ì´ë¯¸ ìˆìœ¼ë©´ ê·¸ëŒ€ë¡œ ì‚¬ìš©
        if not choices or len(choices) < 4:
            # choicesê°€ ì—†ìœ¼ë©´ ìƒˆë¡œ ìƒì„±
            if len(distractors) < 3:
                # ì˜¤ë‹µì´ ë¶€ì¡±í•˜ë©´ ë¬¸ë‹¨ì—ì„œ ì¶”ì¶œ
                nouns = self._extract_nouns_from_paragraph(paragraph)
                for n in nouns:
                    if self._is_valid_distractor(n, correct_answer) and n not in distractors:
                        distractors.append(n)
                        if len(distractors) >= 3:
                            break

            choices = [correct_answer] + distractors[:3]
            random.shuffle(choices)

        return {
            'type': 'reading_comprehension',
            'age_level': age_level,
            'context': paragraph,
            'question': question,
            'choices': choices,
            'correct_answer': correct_answer,
            'correct_index': choices.index(correct_answer) if correct_answer in choices else 0
        }

    def verify_answer(self, question_data: dict, user_choice_index: int) -> dict:
        """ë‹µì•ˆ ê²€ì¦"""
        is_correct = (user_choice_index == question_data.get('correct_index', -1))

        return {
            'correct': is_correct,
            'age_level': question_data.get('age_level', 0),
            'correct_answer': question_data.get('correct_answer', ''),
            'user_answer': question_data.get('choices', [])[user_choice_index] if user_choice_index < len(question_data.get('choices', [])) else ''
        }

    def generate_qna_from_paragraph(self, age: int, paragraph: str, db_words: list[str] = None) -> dict:
        """
        T5 ëª¨ë¸ë¡œ QnA ìƒì„± + ì˜¤ë‹µ ìƒì„±

        Args:
            age: ë‚œì´ë„ (ì—°ë ¹)
            paragraph: ë¬¸ë‹¨
            db_words: DBì—ì„œ ê°€ì ¸ì˜¨ ë‹¨ì–´ ë¦¬ìŠ¤íŠ¸ (ì˜¤ë‹µ í›„ë³´ìš©)

        Returns:
            dict: {question, answer, distractors, choices}
        """
        if not self.__class__._model or not self.__class__._tokenizer:
            return {"error": "ëª¨ë¸ì´ ë¡œë“œë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.", "question": "", "answer": "", "distractors": [], "choices": []}

        # T5 ëª¨ë¸ ì‹¤í–‰
        prompt = f"ë¬¸ë‹¨ì„ ì½ê³  {age}ì„¸ ìˆ˜ì¤€ì˜ ì§ˆë¬¸ê³¼ ì •ë‹µì„ ë§Œë“¤ì–´ ì£¼ì„¸ìš”.\n\në¬¸ë‹¨: {paragraph}"
        inputs = self.__class__._tokenizer(
            prompt,
            return_tensors="pt",
            truncation=True,
            max_length=512
        ).to(self.__class__._device)

        with torch.no_grad():
            outputs = self.__class__._model.generate(
                **inputs,
                max_new_tokens=128,
                temperature=0.9,
                top_p=0.9,
                do_sample=True,
                num_return_sequences=1
            )

        result = self.__class__._tokenizer.decode(outputs[0], skip_special_tokens=True)

        # íŒŒì‹±
        answer_patterns = [r"ì •ë‹µ\s*[:ï¼š]\s*", r"ë‹µ\s*[:ï¼š]\s*", r"Answer\s*[:ï¼š]\s*"]
        question, answer = result, ""

        for pattern in answer_patterns:
            if re.search(pattern, result):
                parts = re.split(pattern, result, maxsplit=1)
                question = parts[0].strip()
                answer = parts[1].strip() if len(parts) > 1 else ""
                break

        # ì§ˆë¬¸ ì •ë¦¬
        question = re.sub(r"^(ì§ˆë¬¸\s*[:ï¼š]\s*)", "", question).strip()
        question = self.clean_question(question)

        # ì •ë‹µì´ ì—†ìœ¼ë©´ ì˜¤ë‹µë„ ìƒì„± ë¶ˆê°€
        if not answer:
            return {
                "question": question,
                "answer": answer,
                "distractors": [],
                "choices": []
            }

        # ì˜¤ë‹µ ìƒì„±
        distractors = self._generate_distractors(answer, paragraph, db_words, age)

        # ì„ íƒì§€ ìƒì„±
        all_choices = list(set(distractors + [answer]))
        random.shuffle(all_choices)

        return {
            "question": question,
            "answer": answer,
            "distractors": distractors,
            "choices": all_choices
        }


    # def load_json_files(self) -> list[dict]:
    #     """JSON íŒŒì¼ë“¤ì„ ë¡œë“œ"""
    #     json_files = []
    #
    #     if not os.path.exists(JSON_DATA_PATH):
    #         print(f"âš ï¸ JSON ë°ì´í„° ê²½ë¡œê°€ ì¡´ì¬í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤: {JSON_DATA_PATH}")
    #         return []
    #
    #     for filename in os.listdir(JSON_DATA_PATH):
    #         if filename.endswith('.json'):
    #             filepath = os.path.join(JSON_DATA_PATH, filename)
    #             try:
    #                 with open(filepath, 'r', encoding='utf-8') as f:
    #                     data = json.load(f)
    #                     # ë¦¬ìŠ¤íŠ¸ë¡œ ê°ì‹¸ì ¸ ìˆëŠ” ê²½ìš° ì²˜ë¦¬
    #                     if isinstance(data, list):
    #                         json_files.extend(data)
    #                     else:
    #                         json_files.append(data)
    #             except Exception as e:
    #                 print(f"âš ï¸ JSON ë¡œë“œ ì‹¤íŒ¨ ({filename}): {e}")
    #
    #     return json_files

    def load_json_file(self) -> list[dict]:
        """ë‹¨ì¼ JSON íŒŒì¼(labeled_fairytale.json) ë¡œë“œ"""
        try:
            with open(filepath, 'r', encoding='utf-8') as f:
                data = json.load(f)
                # ë¦¬ìŠ¤íŠ¸ë¡œ ê°ì‹¸ì ¸ ìˆëŠ” ê²½ìš° ì²˜ë¦¬
                if isinstance(data, list):
                    return data
                else:
                    return [data]
        except Exception as e:
            print(f"âš ï¸ JSON ë¡œë“œ ì‹¤íŒ¨ ({filepath}): {e}")
            return []

    @staticmethod
    def create_paragraph_from_sentences(labeled_text: list[dict], index: int) -> tuple[str, int]:
        """
        labeled_textì—ì„œ ì—°ì†ëœ 3ê°œ ë¬¸ì¥ì„ ì´ì–´ë¶™ì—¬ ë¬¸ë‹¨ ìƒì„±

        Args:
            labeled_text: [{"sentence": "...", "difficulty": 7}, ...]
            index: ì„ íƒëœ ë¬¸ì¥ì˜ ì¸ë±ìŠ¤

        Returns:
            (paragraph, avg_difficulty)
        """
        if not labeled_text or index >= len(labeled_text):
            return "", 7

        # í˜„ì¬ ë¬¸ì¥ ì•ë’¤ë¡œ 1ê°œì”© (ì´ 3ê°œ)
        start_idx = max(0, index - 1)
        end_idx = min(len(labeled_text), index + 2)

        selected_sentences = labeled_text[start_idx:end_idx]

        def clean_sentence(s):
            s = str(s).strip()
            # 1. ë¬¸ì¥ ë§¨ ì•ì˜ ìˆ«ìì™€ ë§ˆì¹¨í‘œ/ê´„í˜¸, ê³µë°± ì œê±° (ì˜ˆ: "1. ë¬¸ì¥" -> "ë¬¸ì¥")
            s = re.sub(r'^\s*[\d\.\)]+\s*', '', s)
            # 2. ë¶ˆí•„ìš”í•œ ê³µë°± ì •ë¦¬
            s = re.sub(r'\s+', ' ', s)

            # 3. ğŸ¯ í•µì‹¬ ìˆ˜ì •: ë¬¸ì¥ ëì´ ë§ˆì¹¨í‘œ, ë¬¼ìŒí‘œ, ëŠë‚Œí‘œë¡œ ëë‚˜ì§€ ì•Šìœ¼ë©´ ë§ˆì¹¨í‘œë¥¼ ì¶”ê°€
            if not re.search(r'[.?!]$', s):
                s += '.'

            return s.strip()

        cleaned_sentences = [clean_sentence(item["sentence"]) for item in selected_sentences]

        # ë¬¸ì¥ë“¤ì„ ì´ì–´ë¶™ì´ê¸°
        paragraph = " ".join(cleaned_sentences)

        # í‰ê·  ë‚œì´ë„ ê³„ì‚°
        difficulties = [item.get("difficulty", 7) for item in selected_sentences]
        avg_difficulty = int(sum(difficulties) / len(difficulties))

        return paragraph, avg_difficulty


    def generate_random_paragraphs(self, num_paragraphs: int = 10) -> list[tuple[str, int]]:
        """
        JSON íŒŒì¼ì—ì„œ ëœë¤ìœ¼ë¡œ ë¬¸ë‹¨ ìƒì„±

        Args:
            num_paragraphs: ìƒì„±í•  ë¬¸ë‹¨ ê°œìˆ˜

        Returns:
            [(paragraph, difficulty), ...]
        """
        all_data = self.load_json_file()

        if not all_data:
            raise ValueError("JSON ë°ì´í„°ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")

        # labeled_textê°€ ìˆëŠ” ê°ì²´ë§Œ í•„í„°ë§
        valid_objects = [obj for obj in all_data if "labeled_text" in obj and obj["labeled_text"]]

        if len(valid_objects) < num_paragraphs:
            print(f"âš ï¸ ìš”ì²­í•œ ê°œìˆ˜({num_paragraphs})ë³´ë‹¤ ì ì€ ë°ì´í„°({len(valid_objects)})ë§Œ ìˆìŠµë‹ˆë‹¤.")
            num_paragraphs = len(valid_objects)

        # ëœë¤ìœ¼ë¡œ ê°ì²´ ì„ íƒ
        selected_objects = random.sample(valid_objects, num_paragraphs)

        paragraphs = []
        for obj in selected_objects:
            labeled_text = obj["labeled_text"]

            # labeled_text ë‚´ì—ì„œ ëœë¤í•˜ê²Œ í•˜ë‚˜ ì„ íƒ
            if len(labeled_text) >= 3:
                # ì•ë’¤ë¡œ 1ê°œì”© ê°€ì ¸ì˜¬ ìˆ˜ ìˆëŠ” ì¸ë±ìŠ¤ ì„ íƒ
                valid_indices = range(1, len(labeled_text) - 1)
                if valid_indices:
                    random_index = random.choice(list(valid_indices))
                else:
                    random_index = 0
            else:
                random_index = 0

            paragraph, difficulty = self.create_paragraph_from_sentences(labeled_text, random_index)
            paragraphs.append((paragraph, difficulty))

        return paragraphs


if __name__ == '__main__':
    assessment = ReadingAssessment()
    try:
        # ... ë¬¸ë‹¨ ìƒì„± ë¡œì§ ...
        paragraphs = assessment.generate_random_paragraphs(num_paragraphs=1)
        if paragraphs:
            paragraph, difficulty = paragraphs[0]
            # ...
            qna_result = assessment.generate_qna_from_paragraph(age=difficulty, paragraph=paragraph)
            # ...
            question_data = assessment.create_question_from_qna(paragraph, qna_result)

            print("\n--- â— ìµœì¢… Question ê°ì²´ í™•ì¸ â— ---")
            import json

            # âš ï¸ ì´ ì¶œë ¥ì—ì„œ 'choices' ë°°ì—´ì´ 4ê°œì˜ í•­ëª©ì„ í¬í•¨í•˜ê³  ìˆëŠ”ì§€ í™•ì¸í•´ì•¼ í•©ë‹ˆë‹¤.
            print(json.dumps(question_data, ensure_ascii=False, indent=4))
        else:
            print("\nâš ï¸ ë¬¸ë‹¨ ìƒì„± ì‹¤íŒ¨: JSON íŒŒì¼ ë¡œë“œ ë¬¸ì œì¼ ìˆ˜ ìˆìŠµë‹ˆë‹¤.")
    except Exception as e:
        print(f"\nâŒ ë¬¸ì œ ìƒì„± ë¡œì§ ì‹¤í–‰ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")