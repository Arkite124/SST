import os
import re
import torch
import requests
from sentence_transformers import SentenceTransformer
from backend.Ai.ai_common.gpu_start import get_device_cuda
from backend.Ai.db.pg_connect import get_book_titles  # sentiment í¬í•¨í•´ì„œ ê°€ì ¸ì˜¤ê¸°

# ---------------------------
# í™˜ê²½ ë³€ìˆ˜ / ì„¤ì •
# ---------------------------
device = get_device_cuda()
model_name = "snunlp/KR-SBERT-V40K-klueNLI-augSTS"
MODEL = SentenceTransformer(model_name, device=device)
EMBEDDING_PATH = "../data/book_embeddings_naver.pt"
CLIENT_ID = os.getenv("NAVER_CLIENT_ID")
CLIENT_SECRET = os.getenv("NAVER_CLIENT_SECRET")
NAVER_URL = "https://openapi.naver.com/v1/search/book.json"

# ---------------------------
# ë„¤ì´ë²„ APIì—ì„œ ì±… ì •ë³´ ê°€ì ¸ì˜¤ê¸°
# ---------------------------
def fetch_book_from_naver(title):
    headers = {"X-Naver-Client-Id": CLIENT_ID, "X-Naver-Client-Secret": CLIENT_SECRET}
    params = {"query": title, "display": 1}
    try:
        resp = requests.get(NAVER_URL, headers=headers, params=params, timeout=10)
        resp.raise_for_status()
        items = resp.json().get("items", [])
        if not items:
            return None
        it = items[0]
        return {
            "title": re.sub(r"<[^>]+>", "", it.get("title", "")),
            "author": re.sub(r"\s*,\s*", ", ", it.get("author", "")) or "ì •ë³´ ì—†ìŒ",
            "isbn": it.get("isbn", "ì •ë³´ ì—†ìŒ").split()[0],
            "description": re.sub(r"<[^>]+>", "", it.get("description", "")) or "ì •ë³´ ì—†ìŒ",
            "image": it.get("image", "ì •ë³´ ì—†ìŒ"),
            "link": it.get("link", None),
            "source": "naver"
        }
    except Exception as e:
        print(f"[NAVER ERROR] {title}: {e}")
        return None

# ---------------------------
# ì‚¬ìš©ì ë²¡í„° ê³„ì‚° (ê°ì • ê¸°ë°˜ ê°€ì¤‘ì¹˜ í¬í•¨)
# ---------------------------
def compute_user_vector(all_books, embeddings_tensor, read_titles_with_sentiment, model):
    """
    read_titles_with_sentiment: [(title, author, sentiment), ...]
    """
    if not read_titles_with_sentiment:
        return None

    title2idx = {b["title"]: i for i, b in enumerate(all_books)}
    weighted_vecs, total_weight = [], 0.0

    for i, (t, _, sentiment) in enumerate(read_titles_with_sentiment):
        # ìµœì‹ ìˆœ ê°€ì¤‘ì¹˜
        recency_w = max(1.0 - 0.2 * i, 0.2)

        # ê°ì • ê¸°ë°˜ ê°€ì¤‘ì¹˜
        if sentiment == "positive":
            sentiment_w = 1.2
        elif sentiment == "neutral":
            sentiment_w = 1.0
        elif sentiment == "negative":
            sentiment_w = 0.6
        else:
            sentiment_w = 1.0  # null ì²˜ë¦¬

        w = recency_w * sentiment_w

        idx = title2idx.get(t)
        if idx is not None and idx < embeddings_tensor.size(0):
            weighted_vecs.append(embeddings_tensor[idx].to(device) * w)
            total_weight += w
        else:
            # .ptì— ì—†ëŠ” ì±…ì€ ë„¤ì´ë²„ API ê²€ìƒ‰ í›„ ì„ë² ë”©
            info = fetch_book_from_naver(t)
            if info:
                new_emb = model.encode([info["title"] + " " + info["description"]],
                                       convert_to_tensor=True).to(device)
                embeddings_tensor = torch.cat([embeddings_tensor, new_emb])
                all_books.append(info)
                weighted_vecs.append(new_emb[0] * w)
                total_weight += w
                # .pt íŒŒì¼ ê°±ì‹ 
                torch.save({"books": all_books, "embeddings": embeddings_tensor.cpu()}, EMBEDDING_PATH)

    return sum(weighted_vecs) / total_weight if weighted_vecs else None

# ---------------------------
# ì¶”ì²œ ê²°ê³¼ ê³„ì‚°
# ---------------------------
def get_recommendations(all_books, embeddings_tensor, user_vec, read_titles_with_sentiment, top_n=15, sim_threshold=0.6):
    read_titles_set = {t for t, _, _ in read_titles_with_sentiment}

    if user_vec is None:
        # ì½ì€ ì±… ì œì™¸ + ì œëª© ì¤‘ë³µ ì œê±°
        seen_titles = set()
        valid_books = []
        for b in all_books:
            t = b["title"]
            if t not in read_titles_set and t not in seen_titles:
                valid_books.append(b)
                seen_titles.add(t)
        sampled = valid_books[:top_n] if len(valid_books) >= top_n else valid_books
        return [(all_books.index(b), 0.0) for b in sampled]

    embeddings_tensor = embeddings_tensor.to(device)
    cos_sim = torch.nn.functional.cosine_similarity(user_vec.unsqueeze(0), embeddings_tensor, dim=1).cpu().numpy()

    # ì½ì€ ì±… ì œì™¸ + ì œëª© ì¤‘ë³µ ì œê±°
    seen_titles = set()
    valid_indices = []
    for i, b in enumerate(all_books):
        t = b["title"]
        if t not in read_titles_set and t not in seen_titles and i < len(embeddings_tensor):
            valid_indices.append(i)
            seen_titles.add(t)

    filtered_indices = [i for i in valid_indices if cos_sim[i] >= sim_threshold]

    if len(filtered_indices) < top_n:
        remaining_needed = top_n - len(filtered_indices)
        remaining_sorted = sorted(
            [i for i in valid_indices if i not in filtered_indices],
            key=lambda i: cos_sim[i], reverse=True
        )
        filtered_indices.extend(remaining_sorted[:remaining_needed])

    # ìœ ì‚¬ë„ ìˆœìœ¼ë¡œ top_n
    sorted_indices = sorted(filtered_indices, key=lambda i: cos_sim[i], reverse=True)[:top_n]

    return [(i, float(cos_sim[i])) for i in sorted_indices]

# ---------------------------
# ì¶”ì²œ ì‹¤í–‰
# ---------------------------
def run_book_recommendation(user_id=1, model=None, embedding_path=EMBEDDING_PATH):
    if model is None:
        model = SentenceTransformer(model_name, device=device)

    if not os.path.exists(embedding_path):
        raise FileNotFoundError(f"{embedding_path} ì¡´ì¬í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤. ì„ë² ë”© íŒŒì¼ì„ ë¨¼ì € ë§Œë“¤ì–´ì£¼ì„¸ìš”.")

    data = torch.load(embedding_path, map_location=device)
    all_books = data["books"]
    embeddings_tensor = data["embeddings"]

    # sentiment í¬í•¨í•´ì„œ DBì—ì„œ ì½ì€ ì±… ê°€ì ¸ì˜¤ê¸°
    read_titles_with_sentiment = get_book_titles(user_id)

    user_vec = compute_user_vector(all_books, embeddings_tensor, read_titles_with_sentiment, model)
    rec_indices = get_recommendations(all_books, embeddings_tensor, user_vec, read_titles_with_sentiment)

    final_books = []
    for idx, sim in rec_indices:
        if idx >= len(all_books):
            continue
        book = all_books[idx].copy()
        book["sim"] = sim
        final_books.append(book)

    return final_books

# ---------------------------
# main
# ---------------------------
if __name__ == "__main__":
    recs = run_book_recommendation(user_id=1, model=MODEL)

    print("\n" + "=" * 80)
    print("ğŸ“š ê°ì • ê¸°ë°˜ ì¶”ì²œ ë„ì„œ ëª©ë¡")
    print("=" * 80)
    for idx, book in enumerate(recs, 1):
        print(f"\n{idx}. ğŸ“– {book.get('title', 'ì •ë³´ ì—†ìŒ')}")
        print(f"    ì €ì: {book.get('author', 'ì •ë³´ ì—†ìŒ')}")
        print(f"    ISBN: {book.get('isbn', 'ì •ë³´ ì—†ìŒ')}")
        print(f"    ì„¤ëª…: {book.get('description', 'ì •ë³´ ì—†ìŒ')}")
        print(f"    ì´ë¯¸ì§€: {book.get('image', 'ì •ë³´ ì—†ìŒ')}")
        print(f"    ë§í¬: {book.get('link', 'ì •ë³´ ì—†ìŒ')}")
        print(f"    ìœ ì‚¬ë„: {book.get('sim', 0.0):.3f}")
    print("\n" + "=" * 80)
