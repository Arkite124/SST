import os
import time
import ast
import torch
from sentence_transformers import SentenceTransformer, util
from ai_common.gpu_start import get_device_cuda

# -----------------------------
# ì„¤ì •
# -----------------------------
HUGGINGFACE_MODEL_ID = "cath1616/similar_word_corse_fine_tunig_model"
EMB_PATH = "/data/corpus_embeddings.pt"

model = None
device = None


# -----------------------------
# 1. í—ˆê¹…í˜ì´ìŠ¤ ëª¨ë¸ ë¡œë“œ
# -----------------------------
def ensure_model_loaded():
    global model, device
    if model is not None:
        return model, device

    device = get_device_cuda()

    print(f"[Info] í—ˆê¹…í˜ì´ìŠ¤ ëª¨ë¸ ë¡œë“œ ì¤‘... ({HUGGINGFACE_MODEL_ID})")
    model = SentenceTransformer(HUGGINGFACE_MODEL_ID, device=device)
    print(f"[Info] í—ˆê¹…í˜ì´ìŠ¤ ëª¨ë¸ ë¡œë“œ ì™„ë£Œ ({device})")

    return model, device


# -----------------------------
# 2. ì„ë² ë”© ìºì‹œ ì €ì¥/ë¡œë“œ
# -----------------------------
def save_corpus_embeddings(corpus_words, device_param, path=EMB_PATH):
    """ë‹¨ì–´ ë¦¬ìŠ¤íŠ¸ â†’ ì„ë² ë”© ìºì‹œ ìƒì„± ë° ì €ì¥"""
    m, d = ensure_model_loaded()

    with torch.inference_mode():
        corpus_emb = m.encode(
            corpus_words,
            convert_to_tensor=True,
            normalize_embeddings=True,
            batch_size=128,
            show_progress_bar=True,
            device=device_param,
        ).cpu()

    os.makedirs(os.path.dirname(path), exist_ok=True)
    torch.save({"corpus_words": corpus_words, "corpus_emb": corpus_emb}, path)
    print(f"[Info] ì„ë² ë”© ìºì‹œ ì €ì¥ ì™„ë£Œ: {path}")
    return corpus_emb


def load_corpus_embeddings(path=EMB_PATH):
    if not os.path.exists(path):
        raise FileNotFoundError(f"[Error] '{path}' ì„ë² ë”© íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤.")
    data = torch.load(path, map_location="cpu")
    print(f"[Info] ì„ë² ë”© ìºì‹œ ë¡œë“œ ì™„ë£Œ: {path}")
    return data["corpus_words"], data["corpus_emb"]


# -----------------------------
# 3. ê²€ìƒ‰ í•¨ìˆ˜ ë¹Œë”
# -----------------------------
def build_search_function(corpus_words, corpus_emb, device_param="cpu"):
    m, d = ensure_model_loaded()
    corpus_emb = corpus_emb.to(device_param)

    def similar_words(query_word, topk=10, exclude_self=True):
        """ë¬¸ë§¥ ê¸°ë°˜ ìœ ì‚¬ì–´ ê²€ìƒ‰ (ê¸°ì¤€ ë‹¨ì–´ ì œì™¸ + ì¤‘ë³µ ì œê±°)"""
        with torch.inference_mode():
            q_emb = m.encode(
                [query_word],
                convert_to_tensor=True,
                normalize_embeddings=True,
                device=device_param
            )
            sims = util.cos_sim(q_emb, corpus_emb)[0]

            if exclude_self and query_word in corpus_words:
                sims[corpus_words.index(query_word)] = -1e9

            vals, idxs = torch.topk(sims, min(topk, len(corpus_words)))
            results = [(corpus_words[i], float(vals[j])) for j, i in enumerate(idxs)]

            # ê¸°ì¤€ë‹¨ì–´ ì œì™¸ + ì¤‘ë³µ ì œê±°
            seen = set()
            filtered = []
            for w, s in results:
                if w not in seen and w != query_word:
                    filtered.append((w, s))
                    seen.add(w)
            return filtered

    return similar_words


# -----------------------------
# 4. ë©”ì¸ ë¡œë”
# -----------------------------
def load_model_and_corpus(emb_path=EMB_PATH, force_rebuild=False):
    """í—ˆê¹…í˜ì´ìŠ¤ ëª¨ë¸ + ë¡œì»¬ ìºì‹œ ì„ë² ë”© ë¶ˆëŸ¬ì˜¤ê¸°"""
    m, d = ensure_model_loaded()

    # ì„ë² ë”© ìºì‹œ ì—†ìœ¼ë©´ ìƒì„±
    if not os.path.exists(emb_path) or force_rebuild:
        print("[Info] ì„ë² ë”© ìºì‹œê°€ ì—†ìŠµë‹ˆë‹¤. ìƒˆë¡œ ìƒì„±í•©ë‹ˆë‹¤...")

        # ì´ ë¶€ë¶„ì€ í•„ìš” ë‹¨ì–´ ë¦¬ìŠ¤íŠ¸ ì§€ì •
        corpus_words = [
            "ì‚¬ê³¼", "ë°°", "í¬ë„", "ë”¸ê¸°", "ë°”ë‚˜ë‚˜", "ê³¼ì¼", "ìŒì‹",
            "ê³µë¶€", "í•™êµ", "êµì‹¤", "ì„ ìƒë‹˜", "í•™ìƒ", "ì¹œêµ¬", "ë†€ì´",
            "ê¸°ì¨", "í–‰ë³µ", "ì‚¬ë‘", "ê°ì •", "ë§ˆìŒ", "ì›ƒìŒ", "ëˆˆë¬¼"
        ]

        save_corpus_embeddings(corpus_words, d, emb_path)
        corpus_words, corpus_emb = corpus_words, torch.load(emb_path)["corpus_emb"]
    else:
        corpus_words, corpus_emb = load_corpus_embeddings(emb_path)

    similar_fn = build_search_function(corpus_words, corpus_emb, d)
    return similar_fn


# -----------------------------
# 5. í…ŒìŠ¤íŠ¸
# -----------------------------
if __name__ == "__main__":
    print("=" * 60)
    print("ğŸ”¹ í—ˆê¹…í˜ì´ìŠ¤ ëª¨ë¸ ê¸°ë°˜ ìœ ì‚¬ì–´ ì¶”ì²œ í…ŒìŠ¤íŠ¸")
    print("=" * 60)

    similar_fn = load_model_and_corpus()
    word_base = "ì‚¬ê³¼"

    start_time = time.time()
    candidates = similar_fn(word_base, topk=5)
    end_time = time.time()

    print(f"\nğŸ” '{word_base}' ìœ ì‚¬ì–´ ì¶”ì²œ:")
    for w, score in candidates:
        print(f"  - {w:<10s} ({score:.4f})")

    print(f"\nâ± ê³„ì‚° ì‹œê°„: {end_time - start_time:.4f}ì´ˆ")
