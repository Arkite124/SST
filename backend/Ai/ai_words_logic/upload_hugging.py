"""
í—ˆê¹…í˜ì´ìŠ¤ì— SentenceTransformer ëª¨ë¸ ì—…ë¡œë“œí•˜ê¸°
"""
import os
from sentence_transformers import SentenceTransformer
from huggingface_hub import HfApi, login, whoami

# =============================================
# ì„¤ì •
# =============================================
LOCAL_MODEL_PATH = os.path.join(os.path.dirname(__file__), "../data/output_kids_words")
HF_REPO_ID = "cath1616/similar_word_corse_fine_tunig_model"
HF_TOKEN = os.getenv("HUGGINGFACE_TOKEN")  # í™˜ê²½ë³€ìˆ˜ì—ì„œ ê°€ì ¸ì˜¤ê¸°

# =============================================
# 1. í—ˆê¹…í˜ì´ìŠ¤ ë¡œê·¸ì¸
# =============================================
print("=" * 60)
print("í—ˆê¹…í˜ì´ìŠ¤ ëª¨ë¸ ì—…ë¡œë“œ")
print("=" * 60)

# í† í° í™•ì¸
if not HF_TOKEN:
    print("âš ï¸  í™˜ê²½ë³€ìˆ˜ HUGGINGFACE_TOKENì´ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
    print("ğŸ’¡ ë‹¤ìŒ ë°©ë²• ì¤‘ í•˜ë‚˜ë¥¼ ì„ íƒí•˜ì„¸ìš”:\n")
    print("ë°©ë²• 1) í™˜ê²½ë³€ìˆ˜ ì„¤ì •")
    print("  Windows: set HUGGINGFACE_TOKEN=your_token_here")
    print("  Linux/Mac: export HUGGINGFACE_TOKEN=your_token_here\n")
    print("ë°©ë²• 2) .env íŒŒì¼ì— ì¶”ê°€")
    print("  HUGGINGFACE_TOKEN=your_token_here\n")
    print("ë°©ë²• 3) í„°ë¯¸ë„ì—ì„œ ë¡œê·¸ì¸")
    print("  huggingface-cli login\n")

    # ì´ë¯¸ ë¡œê·¸ì¸ë˜ì–´ ìˆëŠ”ì§€ í™•ì¸
    try:
        user_info = whoami()
        print(f"âœ… ì´ë¯¸ ë¡œê·¸ì¸ë˜ì–´ ìˆìŠµë‹ˆë‹¤: {user_info['name']}")
    except Exception:
        print("âŒ ë¡œê·¸ì¸ì´ í•„ìš”í•©ë‹ˆë‹¤.")
        print("   í„°ë¯¸ë„ì—ì„œ 'huggingface-cli login' ì‹¤í–‰ í›„ ë‹¤ì‹œ ì‹œë„í•˜ì„¸ìš”.")
        exit(1)
else:
    # í† í°ìœ¼ë¡œ ë¡œê·¸ì¸
    try:
        login(token=HF_TOKEN, add_to_git_credential=True)
        user_info = whoami()
        print(f"âœ… í—ˆê¹…í˜ì´ìŠ¤ ë¡œê·¸ì¸ ì„±ê³µ: {user_info['name']}")
    except Exception as e:
        print(f"âŒ ë¡œê·¸ì¸ ì‹¤íŒ¨: {e}")
        print("\nğŸ’¡ í•´ê²° ë°©ë²•:")
        print("1. https://huggingface.co/settings/tokens ì—ì„œ í† í° ì¬ë°œê¸‰")
        print("2. í† í° ê¶Œí•œì´ 'Write'ì¸ì§€ í™•ì¸")
        print("3. í„°ë¯¸ë„ì—ì„œ `huggingface-cli login` ì‹¤í–‰")
        exit(1)

# =============================================
# 2. ë¡œì»¬ ëª¨ë¸ ë¡œë“œ ë° í™•ì¸
# =============================================
print("\n" + "=" * 60)
print("ë¡œì»¬ ëª¨ë¸ í™•ì¸")
print("=" * 60)

# ê²½ë¡œ ì •ê·œí™”
LOCAL_MODEL_PATH = os.path.abspath(LOCAL_MODEL_PATH)
print(f"ëª¨ë¸ ê²½ë¡œ: {LOCAL_MODEL_PATH}")

if not os.path.exists(LOCAL_MODEL_PATH):
    print(f"âŒ ë¡œì»¬ ëª¨ë¸ ê²½ë¡œë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
    print("\nğŸ’¡ ë‹¤ìŒì„ í™•ì¸í•˜ì„¸ìš”:")
    print(f"  1. ê²½ë¡œê°€ ì˜¬ë°”ë¥¸ì§€: {LOCAL_MODEL_PATH}")
    print(f"  2. output_kids_words í´ë”ê°€ ì¡´ì¬í•˜ëŠ”ì§€")
    exit(1)

# í•„ìˆ˜ íŒŒì¼ í™•ì¸
required_files = ["config.json", "pytorch_model.bin", "tokenizer_config.json"]
existing_files = []
missing_files = []

for f in required_files:
    file_path = os.path.join(LOCAL_MODEL_PATH, f)
    if os.path.exists(file_path):
        existing_files.append(f)
    else:
        missing_files.append(f)

if existing_files:
    print(f"âœ… ë°œê²¬ëœ íŒŒì¼: {existing_files}")

if missing_files:
    print(f"âš ï¸  ëˆ„ë½ëœ íŒŒì¼: {missing_files}")
    print("\nğŸ’¡ ëˆ„ë½ëœ íŒŒì¼ì´ ìˆì–´ë„ ì—…ë¡œë“œë¥¼ ì‹œë„í•©ë‹ˆë‹¤.")
    print("   (ì¼ë¶€ íŒŒì¼ì€ ë‹¤ë¥¸ ì´ë¦„ì¼ ìˆ˜ ìˆìŠµë‹ˆë‹¤)")

# ëª¨ë¸ ë¡œë“œ ë° í…ŒìŠ¤íŠ¸
try:
    print("\nëª¨ë¸ ë¡œë“œ ì¤‘...")
    model = SentenceTransformer(LOCAL_MODEL_PATH)
    print(f"âœ… ëª¨ë¸ ë¡œë“œ ì„±ê³µ")

    # ëª¨ë¸ í…ŒìŠ¤íŠ¸
    print("ëª¨ë¸ í…ŒìŠ¤íŠ¸ ì¤‘...")
    test_embedding = model.encode(["í…ŒìŠ¤íŠ¸", "í•™êµ", "ê³µë¶€"])
    print(f"âœ… ëª¨ë¸ í…ŒìŠ¤íŠ¸ ì„±ê³µ")
    print(f"   ì„ë² ë”© ì°¨ì›: {test_embedding.shape[1]}")
    print(f"   í…ŒìŠ¤íŠ¸ ìƒ˜í”Œ ìˆ˜: {test_embedding.shape[0]}")

except Exception as e:
    print(f"âŒ ëª¨ë¸ ë¡œë“œ ì‹¤íŒ¨: {e}")
    print("\nğŸ’¡ ê°€ëŠ¥í•œ ì›ì¸:")
    print("  1. ëª¨ë¸ì´ ì œëŒ€ë¡œ ì €ì¥ë˜ì§€ ì•ŠìŒ")
    print("  2. SentenceTransformer ë²„ì „ ë¶ˆì¼ì¹˜")
    print("  3. PyTorch ë²„ì „ ë¬¸ì œ")
    exit(1)

# =============================================
# 3. í—ˆê¹…í˜ì´ìŠ¤ì— ì—…ë¡œë“œ
# =============================================
print("\n" + "=" * 60)
print("í—ˆê¹…í˜ì´ìŠ¤ ì—…ë¡œë“œ ì‹œì‘")
print("=" * 60)
print(f"ëª©ì ì§€: {HF_REPO_ID}")
print("\nâš ï¸  ì—…ë¡œë“œì— ì‹œê°„ì´ ê±¸ë¦´ ìˆ˜ ìˆìŠµë‹ˆë‹¤...\n")

try:
    # SentenceTransformerì˜ push_to_hub ë©”ì„œë“œ ì‚¬ìš©
    model.push_to_hub(
        repo_id=HF_REPO_ID,
        private=False,  # Trueë¡œ ì„¤ì •í•˜ë©´ ë¹„ê³µê°œ ì €ì¥ì†Œ
        commit_message="Upload fine-tuned Korean word similarity model",
        exist_ok=True  # ì €ì¥ì†Œê°€ ì´ë¯¸ ìˆìœ¼ë©´ ë®ì–´ì“°ê¸°
    )
    print(f"\nâœ… ì—…ë¡œë“œ ì„±ê³µ!")
    print(f"ğŸ”— ëª¨ë¸ ë§í¬: https://huggingface.co/{HF_REPO_ID}")

except Exception as e:
    print(f"\nâŒ ì—…ë¡œë“œ ì‹¤íŒ¨: {e}")
    print("\nğŸ’¡ í•´ê²° ë°©ë²•:")
    print("1. í—ˆê¹…í˜ì´ìŠ¤ í† í° ê¶Œí•œ í™•ì¸ (Write ê¶Œí•œ í•„ìš”)")
    print("2. ë„¤íŠ¸ì›Œí¬ ì—°ê²° í™•ì¸")
    print("3. ì €ì¥ì†Œ ì´ë¦„ í™•ì¸ (username/model-name í˜•ì‹)")
    print(f"4. í˜„ì¬ ì €ì¥ì†Œ: {HF_REPO_ID}")
    exit(1)

# =============================================
# 4. ì—…ë¡œë“œ í™•ì¸
# =============================================
print("\n" + "=" * 60)
print("ì—…ë¡œë“œ í™•ì¸")
print("=" * 60)

try:
    api = HfApi()
    files = api.list_repo_files(repo_id=HF_REPO_ID)

    print(f"ğŸ“¦ ì—…ë¡œë“œëœ íŒŒì¼ ëª©ë¡ (ì´ {len(files)}ê°œ):")
    for file in sorted(files):
        print(f"  - {file}")

    # í•„ìˆ˜ íŒŒì¼ í™•ì¸
    required_hf_files = ["config.json", "modules.json", "sentence_bert_config.json"]
    uploaded_required = [f for f in required_hf_files if f in files]

    print(f"\ní•„ìˆ˜ íŒŒì¼ í™•ì¸:")
    for f in required_hf_files:
        status = "âœ…" if f in files else "âŒ"
        print(f"  {status} {f}")

    if len(uploaded_required) >= 2:  # ìµœì†Œ 2ê°œë§Œ ìˆì–´ë„ OK
        print("\nâœ… í•„ìˆ˜ íŒŒì¼ì´ ì—…ë¡œë“œë˜ì—ˆìŠµë‹ˆë‹¤!")
    else:
        missing = set(required_hf_files) - set(uploaded_required)
        print(f"\nâš ï¸  ì¼ë¶€ íŒŒì¼ì´ ëˆ„ë½ë˜ì—ˆì„ ìˆ˜ ìˆìŠµë‹ˆë‹¤: {missing}")
        print("   í•˜ì§€ë§Œ ëª¨ë¸ì€ ì‘ë™í•  ê°€ëŠ¥ì„±ì´ ìˆìŠµë‹ˆë‹¤.")

except Exception as e:
    print(f"âš ï¸  í™•ì¸ ì¤‘ ì˜¤ë¥˜: {e}")
    print("   ì—…ë¡œë“œëŠ” ì„±ê³µí–ˆì„ ìˆ˜ ìˆìŠµë‹ˆë‹¤. ì›¹ì—ì„œ í™•ì¸í•˜ì„¸ìš”.")

# =============================================
# 5. ì‚¬ìš© ì•ˆë‚´
# =============================================
print("\n" + "=" * 60)
print("ì™„ë£Œ!")
print("=" * 60)
print("\nğŸ“– ëª¨ë¸ ì‚¬ìš© ë°©ë²•:")
print("```python")
print("from sentence_transformers import SentenceTransformer")
print(f"model = SentenceTransformer('{HF_REPO_ID}')")
print("embeddings = model.encode(['í…ŒìŠ¤íŠ¸', 'í•™êµ'])")
print("```")
print("\nğŸ”— ì›¹ì—ì„œ í™•ì¸:")
print(f"   https://huggingface.co/{HF_REPO_ID}")
print("=" * 60)